# Notes on possible ways to improve the results of the valuations

1. The sample is filtering for scores above 5 without anything automatically eliminated;
2. All message attributes are collected to allow for richer context over a larger number of answers.
   An example is that valuations should be more accurate answers are provided by the same user ID
   (we need to anonymize them) if that user is known to provide accurate answers;
   Timestamps may be relevant based on updates to languages, lesson updates and teaching methodology
3. Keyword dictionaries can be customized to the module so the processing is faster and relevance scores are
   more pertinent based on the type of content
4. Cross-referencing relevance scores between channels could increase accuracy exponentially
5. Deducting points in the score based on number of emojis, exclamations, etc may be helpful -
   deducting points for specific words needs to be tested
6. TO DO: Pull all clear questions out into a separate json for further processing;
7. TO DO: Anonymize the user ID's so we can track specific users without seeing who they are

This approach involves evaluating each message against several criteria indicative of relevance, like the presence of coding keywords, code blocks, technical terms, or the type of conversation (question, solution, discussion). Each criterion can contribute a certain score, and the total score will indicate the message's overall relevance. Those additional parameters of relevance can help train the bot on how to evaluate discussions as apposed to answering questions, for example;


