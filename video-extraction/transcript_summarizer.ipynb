{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2SztM9z5+ueEhxh/cRid3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa1325c3fe444c7f9b4a98cd01a0ef9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7991c25774a4640a3bec1a1d3996762",
              "IPY_MODEL_21a84112466e4fcc9f9c232f2f787f0b",
              "IPY_MODEL_a645eaa6028e48a5bc8322f9fc763f3c"
            ],
            "layout": "IPY_MODEL_4510986d94c74830a7361b0f2edd981d"
          }
        },
        "a7991c25774a4640a3bec1a1d3996762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec4d891edda44b78383f20900235722",
            "placeholder": "​",
            "style": "IPY_MODEL_46f4ad9bf0734bcba9b48f1c93fdb7b9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "21a84112466e4fcc9f9c232f2f787f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad3431a398a41b0a08f8af0fc57e028",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e069f9a7911148f9aaf7006416ca5c56",
            "value": 3
          }
        },
        "a645eaa6028e48a5bc8322f9fc763f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac8935a691bc417aa8adf39a965d53ce",
            "placeholder": "​",
            "style": "IPY_MODEL_18588631f05e46709bab70d59d79b338",
            "value": " 3/3 [04:11&lt;00:00, 84.89s/it]"
          }
        },
        "4510986d94c74830a7361b0f2edd981d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec4d891edda44b78383f20900235722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f4ad9bf0734bcba9b48f1c93fdb7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ad3431a398a41b0a08f8af0fc57e028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e069f9a7911148f9aaf7006416ca5c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac8935a691bc417aa8adf39a965d53ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18588631f05e46709bab70d59d79b338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dutra-Apex/llm-joc/blob/main/video-extraction/transcript_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description:  \n",
        "This program will summarize a youtube video using the Mistral LLM.  The summaries are based on the youtube auto-genarated closed captioning transcript stored with the video.  This program divides the transcript into time length sections and summarizes each section.  It then summarizes the entire video based on summarizing all the summaries together."
      ],
      "metadata": {
        "id": "FnsfhpyZOZ4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the output when printing in colab\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "      white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "metadata": {
        "id": "Ytf3v5nvGbBx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "  return \"UTF-8\"\n",
        "\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "locale.getdefaultlocale()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q0mmVu_OA4Zw",
        "outputId": "14a90aee-97bc-4473-eb2e-312663f70276"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('en_US', 'UTF-8')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create LLM**\n",
        "\n",
        "The following code is from https://blog.gopenai.com/bye-bye-llama-2-mistral-7b-is-taking-over-get-started-with-mistral-7b-instruct-1504ff5f373c\n"
      ],
      "metadata": {
        "id": "TTyCSMneWSpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.  Import Libraries"
      ],
      "metadata": {
        "id": "3HsYv_NlXblE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM and LangChain libraries"
      ],
      "metadata": {
        "id": "V26fHL2X7-Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -q quiets the output\n",
        "!pip install -qU kaleido python-multipart uvicorn fastapi==0.99.1 typing-extensions==4.5 torch==2.1\n",
        "!pip install -qU accelerate bitsandbytes langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxnmLAoJxrI4",
        "outputId": "03b350a1-7903-4747-fd19-a3c906c7c7ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.29 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "uVfkgpMJYP0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "import tensorflow\n",
        "import torch\n",
        "import pandas as pd\n",
        "import math\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "kQNPqNtQYNN4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If want to load model from google drive"
      ],
      "metadata": {
        "id": "eswCYhwNTnln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ6fZePnTvLV",
        "outputId": "1ceeb9b7-230a-49f7-b1a7-0781e05448c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Mistral-7B-Instruct-v0.2\"\n",
        "# model_path = \"mistralai/Mistral-7B-Instruct-v0.2\""
      ],
      "metadata": {
        "id": "Wv8ECo1RXCJK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.  Download the Mistral 7B Instruct Model and Tokenizer"
      ],
      "metadata": {
        "id": "tauIFVkSXn7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_path, load_in_4bit=True, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "aa1325c3fe444c7f9b4a98cd01a0ef9a",
            "a7991c25774a4640a3bec1a1d3996762",
            "21a84112466e4fcc9f9c232f2f787f0b",
            "a645eaa6028e48a5bc8322f9fc763f3c",
            "4510986d94c74830a7361b0f2edd981d",
            "eec4d891edda44b78383f20900235722",
            "46f4ad9bf0734bcba9b48f1c93fdb7b9",
            "0ad3431a398a41b0a08f8af0fc57e028",
            "e069f9a7911148f9aaf7006416ca5c56",
            "ac8935a691bc417aa8adf39a965d53ce",
            "18588631f05e46709bab70d59d79b338"
          ]
        },
        "id": "uI19EJ0bXuWP",
        "outputId": "54074fe8-1ed9-434e-f0d3-a3a723a3e69a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1325c3fe444c7f9b4a98cd01a0ef9a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pipeline for text generation\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=2000,\n",
        "    do_sample = True\n",
        ")"
      ],
      "metadata": {
        "id": "cC736zU7Y2H2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create insance of llm\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
      ],
      "metadata": {
        "id": "sp3QXWhe4_DJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get list of video ids from playlist"
      ],
      "metadata": {
        "id": "u9GMfbloNPH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "zropPXWJLkVb",
        "outputId": "d76dabb5-6a0b-4b3f-8390-4d3bf9e297f2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import Playlist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T0MZvkOtLx9l",
        "outputId": "cc84b6be-39bd-4325-b5df-7c2966d2b0d1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Playlist object\n",
        "playlist_url = \"https://www.youtube.com/playlist?list=PLuePfAWKCLvXDmUCkglj2na2f4TCvCfLg\"\n",
        "playlist = Playlist(playlist_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dHvZb18VMFrl",
        "outputId": "9e51ca14-c0bb-495e-a54b-ba70c180afc7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get video titles\n",
        "video_data = []\n",
        "for video in playlist.videos:\n",
        "    video_data.append([video.video_id, video.title])\n",
        "\n",
        "video_titles_df = pd.DataFrame(video_data, columns=['video_id', 'title'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CKoCuu1_MZ5o",
        "outputId": "59769c77-ac6a-4813-8321-6e6bf9c9c74d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(video_titles_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "ZN7cLRMuOKnB",
        "outputId": "1204daaf-4787-4beb-cf14-ba1555f10ed1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "      white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title\n",
            "0  QwguYMC9doI        2024-03-28T00:59:31Z - Web Wednesdays Q & A\n",
            "1  o7vB2gaM2YE  2024-03-27T23:30:10Z - Data Science / Open Q &...\n",
            "2  RHH9Rk8_9B0  2024-03-27T21:57:07Z - Web Wed for Explorers &...\n",
            "3  mglK874_zlM  2024-03-27T16:58:23Z - Web Wed for Explorers &...\n",
            "4  s6JUoFCKcHs  2024-03-27T01:24:49Z - Python Party & Dev-in-T...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Video Transcripts\n"
      ],
      "metadata": {
        "id": "sevCU7O4_zkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbnJdZ1T_vRB",
        "outputId": "2a8a9357-0174-4796-b427-73e88e51f1d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the module\n",
        "from youtube_transcript_api import YouTubeTranscriptApi"
      ],
      "metadata": {
        "id": "UJ_KyNtD_ymz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the transcript for a video\n",
        "\n",
        "video_id = \"NoXCHb9ydxQ\"  #From 2024-03-20T01:00:51Z - Python Party & Dev-in-Training Updates. https://www.youtube.com/watch?v=NoXCHb9ydxQ\n",
        "srt = YouTubeTranscriptApi.get_transcript(video_id)"
      ],
      "metadata": {
        "id": "QjL64vLFADso"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert youtube list of objects to pandas dataframe\n",
        "video_df = pd.DataFrame(srt, columns=[\"start\", \"text\"])"
      ],
      "metadata": {
        "id": "rOVWUan3AiRR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(video_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPakIoPaBPg-",
        "outputId": "dffa7f17-874d-4a7d-f775-577a3aabc559"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   start                                     text\n",
            "0  16.00  hello hello hello can everybody hear me\n",
            "1  18.16      okay welcome welcome I hear you yes\n",
            "2  21.96  awesome Joseph awesome good to hear I'm\n",
            "3  24.80     gonna turn my volume up a little bit\n",
            "4  26.92      there we go excellent some familiar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that creates a list of dataframes.  Each dataframe in the list contains a block of video trancription based on the time given by the section_minutes parameter.\n",
        "def get_section_frames(df, section_minutes = 10, back_time_secs = 0):\n",
        "  section_length = section_minutes * 60\n",
        "  end_time = df[\"start\"].max()\n",
        "  n_sections = math.ceil(end_time / section_length)\n",
        "  section_list = []\n",
        "  for i in range(n_sections):\n",
        "    section_df = df[(df[\"start\"]> i* section_length - back_time_secs) & (df[\"start\"] < (i+1)*section_length)]\n",
        "    section_list.append(section_df)\n",
        "  return section_list"
      ],
      "metadata": {
        "id": "_gccmdXC_P0M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that creates a list of text sections from a list of dataframes.  Each text section is made by joining all the text within a dataframe text column.\n",
        "def get_text_from_frames(df_list):\n",
        "  sections_text = []\n",
        "  for df in df_list:\n",
        "    section_text = ''\n",
        "    for index, row in df.iterrows():\n",
        "      section_text += row[\"text\"] + \" \"\n",
        "    sections_text.append(section_text)\n",
        "  return sections_text"
      ],
      "metadata": {
        "id": "KQr6f41U_Ph0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataframe to a list of section text\n",
        "section_minutes = 10\n",
        "sect_list = get_text_from_frames(get_section_frames(video_df, section_minutes = section_minutes))"
      ],
      "metadata": {
        "id": "YO0dfGZACAuD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Summaries"
      ],
      "metadata": {
        "id": "kXzdHDvgDmYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt used to summarize sections within a video\n",
        "def get_prompt():\n",
        "  return f\"\"\"[INSTRUCT] Summarize the following video transcript into a concise paragraph.\n",
        "\n",
        "{context}\n",
        "\n",
        "[/INSTRUCT]\"\"\""
      ],
      "metadata": {
        "id": "EOMrM4gm_qAY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = []\n",
        "for context in sect_list:\n",
        "  prompt = get_prompt()\n",
        "  summary = llm(prompt)\n",
        "  summaries.append(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6el0ubJEMXX",
        "outputId": "039b245f-f566-49a7-9866-6d1679d84a23"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:391: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn('Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all the summaries to have the model summarize the summaries\n",
        "combined_summary = \"\\n\".join(summaries)"
      ],
      "metadata": {
        "id": "9dUEdhCgGKU6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt =  f\"\"\"[INSTRUCT] Summarize the following compiled summaries in a concise paragraph.\n",
        "\n",
        "{combined_summary}\n",
        "\n",
        "[/INSTRUCT]\"\"\""
      ],
      "metadata": {
        "id": "dW9oFbtfryEr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_summary = llm(summary_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIyHdlA2FuQ7",
        "outputId": "4cd23586-f9a2-4942-adb2-9dee9fd27d2e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print summaries\n",
        "print(\"Summary of the video:\")\n",
        "print(complete_summary)\n",
        "print()\n",
        "print(\"Section summaries:\")\n",
        "for i in range(len(summaries)):\n",
        "  print(f\"{i*section_minutes} - {(i+1)*section_minutes} minutes.\", summaries[i])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aq9vEfXHFTc",
        "outputId": "8134ac8e-b421-4f7c-f549-ef2d800ea7cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of the video:\n",
            " During the coding training session, the speaker welcomed attendees and shared their excitement about the topic of the night: dictionaries. They encouraged participants to share their achievements in their coding journey and emphasized the importance of persistence and resilience. The session then transitioned into a training on dictionaries, a data structure used to store key-value pairs. Dictionaries offer more flexibility than lists and are commonly used in web development. The speaker demonstrated creating a dictionary in Python and discussed its advantages, such as faster lookups and the ability to create variables on the fly. They also compared dictionaries to lists and emphasized their importance in programming. Participants shared their experiences with coding challenges, discussing issues they encountered when running code locally versus in production environments. They advised taking a step-by-step approach to problem-solving and emphasized the importance of testing code thoroughly before deployment. In the second month of the coding training, students learned about advanced problem-solving, including the creation and writing of libraries. The instructor encouraged students to avoid using library functions and emphasized the importance of understanding coding concepts even when Google fails. They also encouraged students to seek feedback from their peers and announced upcoming changes to the program, including a VIP membership offering direct access to the instructor for faster progress.\n",
            "\n",
            "Section summaries:\n",
            "0 - 10 minutes.  The speaker began the session by welcoming attendees and expressing excitement for the topic of the night, which was a training on dictionaries. They encouraged participants to share their wins, achievements, or milestones in their coding journey. A few attendees shared their victories, including finishing long-awaited projects and completing challenging tutorials. The speaker emphasized the importance of persistence and resilience in the face of obstacles and celebrated the determination of those who didn't give up. The session transitioned into an open Q&A format, allowing attendees to ask questions and share their experiences. The speaker discussed their own journey of learning new concepts and emphasized the importance of lifelong learning and gaining practical experience through internships and contributing to the community. They also highlighted the benefits of answering questions for others as a means of reinforcing one's own understanding and building confidence.\n",
            "\n",
            "10 - 20 minutes.  The speaker discussed dictionaries during a training session, explaining that they are a data structure used to store multiple pieces of information. They compared dictionaries to lists, which store information in a sequential order with indices starting at zero. Dictionaries offer more flexibility as they allow users to assign custom keys instead of relying on numerical indices. The speaker emphasized the importance of dictionaries, especially in web development where JSON is commonly used to transfer information between clients and servers. They demonstrated creating a dictionary in Python and highlighted its key-value pair structure.\n",
            "\n",
            "20 - 30 minutes.  This transcript discusses the concept of dictionaries in Python programming, which is a data structure that stores key-value pairs. Dictionaries offer flexibility in creating variables on the fly, and they can be used to approximate sets. The values in a dictionary do not have to be unique, but each key must be unique. To access a value, one uses the key enclosed in square brackets. Dictionaries are commonly used in web development for tasks such as counting word frequencies and analyzing natural language. They differ from lists, which are stored sequentially, as dictionaries allow for faster lookups. Dictionaries can be initialized with various values, including zeros, and their keys can be sorted. Dictionaries can be thought of as a \"row of PO boxes,\" where each key corresponds to a specific value. Dictionaries take up more memory due to the need to allocate space for potential keys and values, but they provide faster access times compared to lists. A hashing function determines where a key is stored in a dictionary. Dictionaries are useful for storing data quickly and require unique keys; the data may or may not have its own natural mapping.\n",
            "\n",
            "30 - 40 minutes.  This transcript discusses the usage and functionality of dictionaries in programming, specifically in Python. Dictionaries are collections of key-value pairs, which can be accessed using the keys. The syntax involves creating curly braces and defining keys and their corresponding values using colons. Keys can be accessed using square brackets, and dictionary size can be determined using the \"length\" function. Functions such as \"clear,\" \"keys,\" \"values,\" and \"get\" are also mentioned, with the \"get\" function allowing for setting default values if a key is not present. The efficiency of dictionary indexing was also briefly touched upon, but the speaker noted that the specific implementation may determine how the computer stores frequently used values. The discussion also covered the differences between lists and dictionaries, including their uses and storage requirements.\n",
            "\n",
            "40 - 50 minutes.  In the video, the speaker discusses the use cases for both dictionaries and databases in programming. For small programs, dictionaries are a faster option for lookup and variable creation, while databases are suitable for large-scale production systems with thousands to millions of users and vast amounts of data. Databases have specific organizational features such as tables and transactions, requiring servers, whereas dictionaries are a data structure for fast lookup and mapping purposes. The speaker uses an analogy of aircraft to explain the differences between the two, emphasizing their distinct areas of application. They also address a viewer's question regarding inconsistencies in handling newlines (`\\n`) between local environments and GitHub, suggesting potential solutions.\n",
            "\n",
            "50 - 60 minutes.  In the discussion, participants shared their experiences with coding challenges and encountered issues when running code locally versus in production environments. They discussed a specific issue involving special characters, such as the M-Dash, which appeared differently across platforms. The group suggested using lookup tables for problematic characters and emphasized the importance of testing code thoroughly before deployment. Additionally, they advised new coders to take a step-by-step approach to solving problems and not to rely solely on search engines for answers. One participant shared an experience of writing a simple script to calculate the average of ten numbers from user input and faced difficulties implementing a continuous input mechanism. They discussed various loop structures, including do-while and sentinel loops, as potential solutions.\n",
            "\n",
            "60 - 70 minutes.  The speaker in the video was attempting to write a program to calculate the average of numbers input by a user until they enter zero. They encountered several issues during the process, including forgetting to copy a necessary line of code and needing to input data into a file instead of directly into the program. They also discussed the importance of testing each piece of code individually and minimizing repetition by putting it in a function. The speaker emphasized their goal of creating an effective learning environment for coding skills within Joy Coing Academy, acknowledging the challenges of keeping up with rapidly evolving technology. They also addressed questions from viewers regarding UTF encodings and implementing do-while loops in languages without do-while statements. Overall, the speaker was engaged with their audience and open to answering additional questions.\n",
            "\n",
            "70 - 80 minutes.  In the second month of their coding training, students learned about advanced problem-solving, including the creation and writing of libraries. They were encouraged to avoid using library functions during this phase to better understand the problem-solving process behind their development. One student shared their experience of converting numbers to binary, which proved challenging but ultimately helped ignite their thinking process. The instructor emphasized the importance of understanding coding concepts even when Google fails and encouraged students to seek feedback from their peers in the Discord community. The instructor also mentioned upcoming changes to the program, including a VIP membership offering direct access to the instructor for faster progress.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save summaries to file\n",
        "filename = \"video_summary.txt\"\n",
        "with open(filename, \"w\") as file:\n",
        "  file.write(\"Summary of the video:\\n\")\n",
        "  file.write(complete_summary)\n",
        "  file.write(\"\\nSection summaries:\\n\")\n",
        "  for i in range(len(summaries)):\n",
        "    file.write(f\"{i*section_minutes} - {(i+1)*section_minutes} minutes. {summaries[i]} \\n\")"
      ],
      "metadata": {
        "id": "VCDb1GrKIcai"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}