{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsYOolcKdbpvn3YhnTO1uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dutra-Apex/llm-joc/blob/mathew-yt-transcripts/Youtube_extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract transcripts from youtube videos\n",
        "Creates youtube objects (video id and title) from each video in a playlist.  Then gets the youtube captions transcripts from the videos.  Stores the data as a json file."
      ],
      "metadata": {
        "id": "IwNeDIjeU5PF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6iuYz4UyjE",
        "outputId": "82528b09-4019-418a-badd-12a67ac1fc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive if you want to permanently store the json file after created\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install and import dependencies"
      ],
      "metadata": {
        "id": "RP-lkBg4XsOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pytube\n",
        "!pip -q install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZej9umDW_7u",
        "outputId": "9e8a7058-1d0a-4352-bac4-cbb306b90dc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/57.6 kB\u001b[0m \u001b[31m786.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m802.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api import TranscriptsDisabled\n",
        "from pytube import Playlist\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "A7ETPYo-g2dJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get list of youtube objects from a playlist"
      ],
      "metadata": {
        "id": "p2oAyQ6-X6tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "playlist_url = \"https://www.youtube.com/playlist?list=PLuePfAWKCLvXDmUCkglj2na2f4TCvCfLg\"\n",
        "playlist = Playlist(playlist_url)  #returns an array of youtube objects"
      ],
      "metadata": {
        "id": "7CeRFT1OVSn6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the id, title, and transcript\n",
        "\n",
        "Store the video_ids, titles, and transcripts as a list.\n",
        "\n",
        "Note:  The output from get_transcript is a list of the following key-pairs [{'text' : caption string, 'start' : start time of caption, 'duration' : duration of caption}, ...].  This code only keeps the text data."
      ],
      "metadata": {
        "id": "mHyHP2ASasRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_data_list = []\n",
        "for video in playlist.videos:\n",
        "  transcript = \"\"\n",
        "  try:\n",
        "    transcript_data = YouTubeTranscriptApi.get_transcript(video.video_id)\n",
        "    for entry in transcript_data:\n",
        "        transcript += f\"{entry['text']}\\n\"\n",
        "  except TranscriptsDisabled:\n",
        "    pass\n",
        "\n",
        "  video_data_list.append({\n",
        "      \"video_id\" : video.video_id,\n",
        "      \"title\" : video.title,\n",
        "      \"transcript\" : transcript\n",
        "      })\n"
      ],
      "metadata": {
        "id": "h-mpa8xFZLL9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store list as a pandas DataFrame\n",
        "video_transcripts_df = pd.DataFrame(video_data_list)"
      ],
      "metadata": {
        "id": "OpF_QOw-xRq3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store as json file\n",
        "filename = \"JofC_transcripts.json\"\n",
        "video_transcripts_df.to_json(filename)"
      ],
      "metadata": {
        "id": "SfMj1m3JxQMo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy json file to Google drive"
      ],
      "metadata": {
        "id": "96Z4o30mqNPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy json file to Google drive to retain file\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "source_filepath = os.path.join(\"/content/\", filename)\n",
        "dest_filepath = os.path.join(\"/content/gdrive/MyDrive/JofC/\", filename)\n",
        "\n",
        "if os.path.exists(source_filepath):\n",
        "  shutil.copy2(source_filepath, dest_filepath)\n",
        "  print(f\"File copied successfully from {source_filepath} to {dest_filepath}\")\n",
        "else:\n",
        "  print(f\"Error: File not found at {source_filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7catYl0hn--p",
        "outputId": "35d9e40b-fc3d-4067-d08f-684f6e65f61d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File copied successfully from /content/JofC_transcripts.json to /content/gdrive/MyDrive/JofC/JofC_transcripts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncated example of transcript\n",
        "print(video_transcripts_df.loc[1, \"transcript\"][:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsB_ZlCg9Xuo",
        "outputId": "637fe759-35bf-4c86-980f-3d2ced225739"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what we need to change in terms of like\n",
            "the end points and whatnot stuff that\n",
            "has already been created with the user\n",
            "thing in mind and whatnot if it was\n",
            "being used in the first\n",
            "place\n",
            "yeah the file tha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter videos based on title keywords"
      ],
      "metadata": {
        "id": "eVd50eYJtGD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_videos = video_transcirpts_df[raw_video_transcirpts_df[\"title\"].str.contains(\"training\", case=False)]"
      ],
      "metadata": {
        "id": "s42tj1aSl-Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "career_videos = videos_df[videos_df[\"title\"].str.contains(\"career\", case=False)]"
      ],
      "metadata": {
        "id": "npXLeRaEn6_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_videos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSasMe-HpGFi",
        "outputId": "55f0067b-dfd9-4810-d0ba-a98424684967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         video_id                                              title  \\\n",
            "121   JMkQqpaSsqc  2024-01-10T02:03:36Z - Python Party & Dev-in-T...   \n",
            "150   G1Qm597rrpI  2024-01-03T02:02:46Z - Python Party & Dev-in-T...   \n",
            "175   fQJ5KHxjlRI  2023-12-22T02:03:15Z - Python Party & Dev-in-T...   \n",
            "182   KdLYKzF_XyI  2023-12-20T02:01:16Z - Python Party & Dev-in-T...   \n",
            "204   wbnxick21aA  2023-12-13T02:00:48Z - Python Party & Dev-in-T...   \n",
            "269   EB3aHmCwyZ8  2023-11-18T21:02:33Z - Live Training on the 7 ...   \n",
            "271   BX6IUDSjNWI  2023-11-18T15:00:35Z - Live Training on the 7 ...   \n",
            "385   Xr2Q5nwUJXs  2023-10-14T13:55:07Z - Live Training on the 7 ...   \n",
            "454   AFzGDqNAvLw  2023-09-23T20:00:34Z - Live Training on the 7 ...   \n",
            "456   m_1KwUXqoOQ  Live Orientation and Live Training on the 7 Ba...   \n",
            "544   io0XVlebY2U  2023-08-26T18:55:53Z - Live Training on the 7 ...   \n",
            "545   mszbOa9We3o  2023-08-26T14:57:43Z - Live Training on the 7 ...   \n",
            "664   y2fJjCnrGM8  2023-07-08T14:01:31Z - Live Training on the 7 ...   \n",
            "702   vClz7VmKBAk  2023-06-17T20:00:55Z - Live Training on the 7 ...   \n",
            "703   wYfI0WIOE-I  2023-06-17T14:03:11Z - Live Training on the 7 ...   \n",
            "745   J4aamM_gTkI  2023-05-20T15:50:55Z - Live Training on the 7 ...   \n",
            "1119  nkWWfoawzl8  10.04.22 @ 11:00AM Student Feedback Training -...   \n",
            "\n",
            "                                             transcript  \n",
            "121   hello welcome\\n[Music]\\nwelcome all right A lo...  \n",
            "150   hello welcome welcome\\nwelcome to the python\\n...  \n",
            "175   hello hello welcome welcome can\\neverybody hea...  \n",
            "182   welcome welcome everyone welcome welcome\\nto t...  \n",
            "204   here we go here we\\ngo welcome come on in guys...  \n",
            "269   all right all right all right can\\neverybody h...  \n",
            "271   hello hello oh thank you Emily I was\\nabout to...  \n",
            "385   all right good morning everybody thank\\nyou so...  \n",
            "454   hello\\nhello hey guys how's it going can you\\n...  \n",
            "456   right\\nHello everybody welcome welcome so I am...  \n",
            "544   foreign\\nhey guys how's it going can you hear ...  \n",
            "545   hello hello hello everyone can everyone\\nhear\\...  \n",
            "664   um right all right all right can you\\nguys hea...  \n",
            "702   hey hey hey how's it going guys can you\\nhear ...  \n",
            "703   thank you\\nall right all right everybody hear ...  \n",
            "745   hey Katrina how's it going\\nall right let's se...  \n",
            "1119  thank you\\nhey Gabriel how's it going good how...  \n"
          ]
        }
      ]
    }
  ]
}
